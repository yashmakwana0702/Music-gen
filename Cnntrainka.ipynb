{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-03-16T02:22:29.654844Z","iopub.status.busy":"2022-03-16T02:22:29.653337Z","iopub.status.idle":"2022-03-16T02:23:43.207708Z","shell.execute_reply":"2022-03-16T02:23:43.206425Z","shell.execute_reply.started":"2022-03-16T02:22:29.654551Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n"]},{"name":"stderr","output_type":"stream","text":["'sudo' is not recognized as an internal or external command,\n","operable program or batch file.\n","'sudo' is not recognized as an internal or external command,\n","operable program or batch file.\n"]},{"name":"stdout","output_type":"stream","text":["Collecting music21\n","  Downloading music21-7.3.1-py3-none-any.whl (22.4 MB)\n","     ---------------------------------------- 22.4/22.4 MB 3.2 MB/s eta 0:00:00\n","Collecting webcolors>=1.5\n","  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n","Collecting chardet\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","     -------------------------------------- 178.7/178.7 KB 3.6 MB/s eta 0:00:00\n","Collecting more-itertools\n","  Downloading more_itertools-8.12.0-py3-none-any.whl (54 kB)\n","     ---------------------------------------- 54.3/54.3 KB 1.4 MB/s eta 0:00:00\n","Requirement already satisfied: numpy in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from music21) (1.22.3)\n","Requirement already satisfied: matplotlib in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from music21) (3.5.1)\n","Collecting jsonpickle\n","  Downloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\n","Requirement already satisfied: joblib in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from music21) (1.1.0)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->music21) (9.0.1)\n","Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->music21) (3.0.7)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->music21) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->music21) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->music21) (4.31.2)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->music21) (21.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib->music21) (1.4.0)\n","Requirement already satisfied: six>=1.5 in c:\\users\\yashm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.16.0)\n","Installing collected packages: webcolors, more-itertools, jsonpickle, chardet, music21\n","Successfully installed chardet-4.0.0 jsonpickle-2.1.0 more-itertools-8.12.0 music21-7.3.1 webcolors-1.11.1\n"]}],"source":["try:\n","    import music21\n","except:\n","    ! pip install music21\n","    ! wget update\n","    ! sudo apt install musescore3 -y"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-03-16T02:23:43.210985Z","iopub.status.busy":"2022-03-16T02:23:43.210673Z","iopub.status.idle":"2022-03-16T02:24:18.549182Z","shell.execute_reply":"2022-03-16T02:24:18.548232Z","shell.execute_reply.started":"2022-03-16T02:23:43.210941Z"},"trusted":true},"outputs":[],"source":["try:\n","    import midi2audio\n","except:\n","    ! pip install midi2audio\n","    ! sudo apt-get update\n","    ! sudo apt-get install fluidsynth -y"]},{"cell_type":"markdown","metadata":{},"source":["Creating something new is a difficult task. Creation does not start from nothing.\n","Perhaps it is finding something new on a well-established foundation.\n","From this perspective, we will be able to create new music through our model.\n","\n","In this notebook, we will learn bach's music through RNN and attention and use it to create new music."]},{"cell_type":"markdown","metadata":{},"source":["--------------------------\n","# Setting Up"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:29:09.369576Z","iopub.status.busy":"2022-03-16T03:29:09.369229Z","iopub.status.idle":"2022-03-16T03:29:10.073884Z","shell.execute_reply":"2022-03-16T03:29:10.073055Z","shell.execute_reply.started":"2022-03-16T03:29:09.369545Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mf:\\Music-gen\\Cnntrainka.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000005?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000005?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000005?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000005?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelCheckpoint, EarlyStopping\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000005?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvis_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_model\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=14'>15</a>\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=15'>16</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=16'>17</a>\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=17'>18</a>\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=18'>19</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=19'>20</a>\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m     <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/keras/__init__.py?line=23'>24</a>\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}],"source":["import IPython\n","from IPython.display import Image, Audio\n","from midi2audio import FluidSynth\n","from music21 import corpus, converter, instrument, note, stream, chord, duration\n","import matplotlib.pyplot as plt\n","import time\n","\n","import os\n","import pickle\n","import keras\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.utils.vis_utils import plot_model\n","\n","import os\n","import numpy as np\n","import glob\n","\n","from keras.layers import LSTM, Input, Dropout, Dense, Activation, Embedding, Concatenate, Reshape\n","from keras.layers import Flatten, RepeatVector, Permute, TimeDistributed\n","from keras.layers import Multiply, Lambda, Softmax\n","import keras.backend as K \n","from keras.models import Model\n","from tensorflow.keras.optimizers import RMSprop\n","\n","from keras.utils import np_utils\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{},"source":["--------------------------\n","# Let's enjoy the original bach music\n","\n","![](https://www.dazebaonews.it/media/k2/items/cache/fe1d1389160c973e96c942135c3a5378_XL.jpg)\n","\n","Picture Credit: https://www.dazebaonews.it/media"]},{"cell_type":"markdown","metadata":{},"source":["**Chordify Method:**\n","> Chordify is a madeup word that we created in music21 for the process of making chords out of non-chords. Chordify powerful tool for reducing a complex score with multiple parts to a succession of chords in one part that represent everything that is happening in the score. \n","\n","Ref: https://web.mit.edu/music21/doc/usersGuide"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:24:24.936781Z","iopub.status.busy":"2022-03-16T02:24:24.936063Z","iopub.status.idle":"2022-03-16T02:24:31.830087Z","shell.execute_reply":"2022-03-16T02:24:31.829206Z","shell.execute_reply.started":"2022-03-16T02:24:24.936732Z"},"trusted":true},"outputs":[],"source":["dataset_name = '../input/classical-music-midi/bach'\n","filename = 'bach_846'\n","file = \"{}/{}.mid\".format(dataset_name, filename)\n","\n","original_score = converter.parse(file).chordify()"]},{"cell_type":"markdown","metadata":{},"source":["**Let's listen to the three performances of bach first.**"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2022-03-16T02:24:31.833094Z","iopub.status.busy":"2022-03-16T02:24:31.832743Z","iopub.status.idle":"2022-03-16T02:24:45.971576Z","shell.execute_reply":"2022-03-16T02:24:45.970622Z","shell.execute_reply.started":"2022-03-16T02:24:31.833058Z"},"trusted":true},"outputs":[],"source":["fs = FluidSynth()\n","file = '../input/classical-music-midi/bach/bach_846.mid'\n","fs.midi_to_audio(file, 'bach_846.wav')\n","IPython.display.Audio(\"bach_846.wav\") "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:24:45.973317Z","iopub.status.busy":"2022-03-16T02:24:45.973039Z","iopub.status.idle":"2022-03-16T02:24:58.929719Z","shell.execute_reply":"2022-03-16T02:24:58.928911Z","shell.execute_reply.started":"2022-03-16T02:24:45.973287Z"},"trusted":true},"outputs":[],"source":["fs.midi_to_audio('../input/classical-music-midi/bach/bach_847.mid', 'bach_847.wav')\n","IPython.display.Audio(\"bach_847.wav\") "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:24:58.931557Z","iopub.status.busy":"2022-03-16T02:24:58.931219Z","iopub.status.idle":"2022-03-16T02:25:10.560738Z","shell.execute_reply":"2022-03-16T02:25:10.559578Z","shell.execute_reply.started":"2022-03-16T02:24:58.931529Z"},"trusted":true},"outputs":[],"source":["fs.midi_to_audio('../input/classical-music-midi/bach/bach_850.mid', 'bach_850.wav')\n","IPython.display.Audio(\"bach_850.wav\") "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:10.562547Z","iopub.status.busy":"2022-03-16T02:25:10.562304Z","iopub.status.idle":"2022-03-16T02:25:21.152833Z","shell.execute_reply":"2022-03-16T02:25:21.151866Z","shell.execute_reply.started":"2022-03-16T02:25:10.562518Z"},"trusted":true},"outputs":[],"source":["original_score.show()"]},{"cell_type":"markdown","metadata":{},"source":["---------------------\n","# Extracting the data\n","\n","It loops through the score and extracts the pitch and time of each note (and rest) into two lists. The entire chord is stored as a string, and individual notes in the chord are separated by dots. The male after the name of each note refers to the octave to which the note belongs."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:21.203615Z","iopub.status.busy":"2022-03-16T02:25:21.202862Z","iopub.status.idle":"2022-03-16T02:25:21.261033Z","shell.execute_reply":"2022-03-16T02:25:21.260281Z","shell.execute_reply.started":"2022-03-16T02:25:21.203567Z"},"trusted":true},"outputs":[],"source":["notes = []\n","durations = []\n","\n","for element in original_score.flat:    \n","    if isinstance(element, chord.Chord):\n","        notes.append('.'.join(n.nameWithOctave for n in element.pitches))\n","        durations.append(element.duration.quarterLength)\n","\n","    if isinstance(element, note.Note):\n","        if element.isRest:\n","            notes.append(str(element.name))\n","            durations.append(element.duration.quarterLength)\n","        else:\n","            notes.append(str(element.nameWithOctave))\n","            durations.append(element.duration.quarterLength)   "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:21.263038Z","iopub.status.busy":"2022-03-16T02:25:21.262508Z","iopub.status.idle":"2022-03-16T02:25:21.288859Z","shell.execute_reply":"2022-03-16T02:25:21.287969Z","shell.execute_reply.started":"2022-03-16T02:25:21.262996Z"},"trusted":true},"outputs":[],"source":["print('\\nduration', 'pitch')\n","idx = 0\n","for n,d in zip(notes,durations):\n","    if idx < 50:\n","        print(d, '\\t', n)\n","    idx = idx + 1   "]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"border: solid 3px blue;\">\n","\n","# Creating Music\n","\n","Here, modeling is done using RNN and atension mechanism, and a new music is composed using this."]},{"cell_type":"markdown","metadata":{},"source":["## Defiing Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:21.290775Z","iopub.status.busy":"2022-03-16T02:25:21.290447Z","iopub.status.idle":"2022-03-16T02:25:21.319037Z","shell.execute_reply":"2022-03-16T02:25:21.318017Z","shell.execute_reply.started":"2022-03-16T02:25:21.29074Z"},"trusted":true},"outputs":[],"source":["def get_music_list(data_folder):    \n","    file_list = glob.glob(os.path.join(data_folder, \"*.mid\"))\n","    parser = converter    \n","    return file_list, parser\n","\n","def create_network(n_notes, n_durations, embed_size = 100, rnn_units = 256, use_attention = False):\n","    notes_in = Input(shape = (None,))\n","    durations_in = Input(shape = (None,))\n","\n","    x1 = Embedding(n_notes, embed_size)(notes_in)\n","    x2 = Embedding(n_durations, embed_size)(durations_in) \n","    x = Concatenate()([x1,x2])\n","    x = LSTM(rnn_units, return_sequences=True)(x)\n","\n","    if use_attention:\n","        x = LSTM(rnn_units, return_sequences=True)(x)\n","        e = Dense(1, activation='tanh')(x)\n","        e = Reshape([-1])(e)\n","        alpha = Activation('softmax')(e)\n","        alpha_repeated = Permute([2, 1])(RepeatVector(rnn_units)(alpha))\n","        c = Multiply()([x, alpha_repeated])\n","        c = Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(rnn_units,))(c)    \n","    else:\n","        c = LSTM(rnn_units)(x)\n","                                    \n","    notes_out = Dense(n_notes, activation = 'softmax', name = 'pitch')(c)\n","    durations_out = Dense(n_durations, activation = 'softmax', name = 'duration')(c)\n","   \n","    model = Model([notes_in, durations_in], [notes_out, durations_out])    \n","\n","    if use_attention:\n","        att_model = Model([notes_in, durations_in], alpha)\n","    else:\n","        att_model = None\n","        \n","    opti = RMSprop(lr = 0.001)\n","    model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy'], optimizer=opti)\n","\n","    return model, att_model\n","\n","\n","def get_distinct(elements):\n","    # Get all pitch names\n","    element_names = sorted(set(elements))\n","    n_elements = len(element_names)\n","    return (element_names, n_elements)\n","\n","def create_lookups(element_names):\n","    # create dictionary to map notes and durations to integers\n","    element_to_int = dict((element, number) for number, element in enumerate(element_names))\n","    int_to_element = dict((number, element) for number, element in enumerate(element_names))\n","    return (element_to_int, int_to_element)    \n","\n","def prepare_sequences(notes, durations, lookups, distincts, seq_len =32):\n","    note_to_int, int_to_note, duration_to_int, int_to_duration = lookups\n","    note_names, n_notes, duration_names, n_durations = distincts\n","\n","    notes_network_input = []\n","    notes_network_output = []\n","    durations_network_input = []\n","    durations_network_output = []\n","\n","    # create input sequences and the corresponding outputs\n","    for i in range(len(notes) - seq_len):\n","        notes_sequence_in = notes[i:i + seq_len]\n","        notes_sequence_out = notes[i + seq_len]\n","        notes_network_input.append([note_to_int[char] for char in notes_sequence_in])\n","        notes_network_output.append(note_to_int[notes_sequence_out])\n","\n","        durations_sequence_in = durations[i:i + seq_len]\n","        durations_sequence_out = durations[i + seq_len]\n","        durations_network_input.append([duration_to_int[char] for char in durations_sequence_in])\n","        durations_network_output.append(duration_to_int[durations_sequence_out])\n","\n","    n_patterns = len(notes_network_input)\n","\n","    # reshape the input into a format compatible with LSTM layers\n","    notes_network_input = np.reshape(notes_network_input, (n_patterns, seq_len))\n","    durations_network_input = np.reshape(durations_network_input, (n_patterns, seq_len))\n","    network_input = [notes_network_input, durations_network_input]\n","\n","    notes_network_output = np_utils.to_categorical(notes_network_output, num_classes=n_notes)\n","    durations_network_output = np_utils.to_categorical(durations_network_output, num_classes=n_durations)\n","    network_output = [notes_network_output, durations_network_output]\n","    return (network_input, network_output)\n","\n","def sample_with_temp(preds, temperature):\n","    if temperature == 0:\n","        return np.argmax(preds)\n","    else:\n","        preds = np.log(preds) / temperature\n","        exp_preds = np.exp(preds)\n","        preds = exp_preds / np.sum(exp_preds)\n","        return np.random.choice(len(preds), p=preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:21.320869Z","iopub.status.busy":"2022-03-16T02:25:21.320618Z","iopub.status.idle":"2022-03-16T02:25:21.335196Z","shell.execute_reply":"2022-03-16T02:25:21.334395Z","shell.execute_reply.started":"2022-03-16T02:25:21.32084Z"},"trusted":true},"outputs":[],"source":["# run params\n","run_folder = '/kaggle/working'\n","\n","store_folder = os.path.join(run_folder, 'store')\n","data_folder ='../input/classical-music-midi/bach'\n","\n","if not os.path.exists('store'):\n","    os.mkdir(os.path.join(run_folder, 'store'))\n","    os.mkdir(os.path.join(run_folder, 'output'))\n","    os.mkdir(os.path.join(run_folder, 'weights'))\n","    os.mkdir(os.path.join(run_folder, 'viz'))\n","\n","mode = 'build'\n","\n","# data params\n","intervals = range(1)\n","seq_len = 32\n","\n","# model params\n","embed_size = 100\n","rnn_units = 256\n","use_attention = True"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-03-16T02:25:21.339458Z","iopub.status.busy":"2022-03-16T02:25:21.339234Z","iopub.status.idle":"2022-03-16T02:25:42.333117Z","shell.execute_reply":"2022-03-16T02:25:42.332393Z","shell.execute_reply.started":"2022-03-16T02:25:21.33943Z"},"trusted":true},"outputs":[],"source":["if mode == 'build':    \n","    music_list, parser = get_music_list(data_folder)\n","    print(len(music_list), 'files in total')\n","\n","    notes = []\n","    durations = []\n","\n","    for i, file in enumerate(music_list):\n","        print(i+1, \"Parsing %s\" % file)\n","        print(file)\n","        original_score = parser.parse(file).chordify()        \n","        for interval in intervals:\n","            score = original_score.transpose(interval)\n","\n","            notes.extend(['START'] * seq_len)\n","            durations.extend([0]* seq_len)\n","\n","            for element in score.flat:                \n","                if isinstance(element, note.Note):\n","                    if element.isRest:\n","                        notes.append(str(element.name))\n","                        durations.append(element.duration.quarterLength)\n","                    else:\n","                        notes.append(str(element.nameWithOctave))\n","                        durations.append(element.duration.quarterLength)\n","                        \n","                if isinstance(element, chord.Chord):\n","                    notes.append('.'.join(n.nameWithOctave for n in element.pitches))\n","                    durations.append(element.duration.quarterLength)\n","\n","    with open(os.path.join(store_folder, 'notes'), 'wb') as f:\n","        pickle.dump(notes, f) \n","    with open(os.path.join(store_folder, 'durations'), 'wb') as f:\n","        pickle.dump(durations, f) \n","else:\n","    with open(os.path.join(store_folder, 'notes'), 'rb') as f:\n","        notes = pickle.load(f)\n","    with open(os.path.join(store_folder, 'durations'), 'rb') as f:\n","        durations = pickle.load(f) "]},{"cell_type":"markdown","metadata":{},"source":["------------------------------------------\n","# Embedding Note and Duration\n","\n","To create a dataset for training the model, we first convert the pitch and tempo into integer values. It doesn't matter what these values are because we use an embedding layer to convert the integer to a vector."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.334363Z","iopub.status.busy":"2022-03-16T02:25:42.334175Z","iopub.status.idle":"2022-03-16T02:25:42.352485Z","shell.execute_reply":"2022-03-16T02:25:42.351542Z","shell.execute_reply.started":"2022-03-16T02:25:42.33434Z"},"trusted":true},"outputs":[],"source":["# get the distinct sets of notes and durations\n","note_names, n_notes = get_distinct(notes)\n","duration_names, n_durations = get_distinct(durations)\n","distincts = [note_names, n_notes, duration_names, n_durations]\n","\n","with open(os.path.join(store_folder, 'distincts'), 'wb') as f:\n","    pickle.dump(distincts, f)\n","\n","# make the lookup dictionaries for notes and dictionaries and save\n","note_to_int, int_to_note = create_lookups(note_names)\n","duration_to_int, int_to_duration = create_lookups(duration_names)\n","lookups = [note_to_int, int_to_note, duration_to_int, int_to_duration]\n","\n","with open(os.path.join(store_folder, 'lookups'), 'wb') as f:\n","    pickle.dump(lookups, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.354609Z","iopub.status.busy":"2022-03-16T02:25:42.354298Z","iopub.status.idle":"2022-03-16T02:25:42.363124Z","shell.execute_reply":"2022-03-16T02:25:42.362388Z","shell.execute_reply.started":"2022-03-16T02:25:42.354569Z"},"trusted":true},"outputs":[],"source":["print('\\nnote_to_int')\n","for i, item in enumerate(note_to_int.items()):\n","    if i < 10:\n","        print(item)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.365081Z","iopub.status.busy":"2022-03-16T02:25:42.364494Z","iopub.status.idle":"2022-03-16T02:25:42.373721Z","shell.execute_reply":"2022-03-16T02:25:42.372962Z","shell.execute_reply.started":"2022-03-16T02:25:42.365038Z"},"trusted":true},"outputs":[],"source":["print('\\nduration_to_int')\n","duration_to_int"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.375862Z","iopub.status.busy":"2022-03-16T02:25:42.375111Z","iopub.status.idle":"2022-03-16T02:25:42.680043Z","shell.execute_reply":"2022-03-16T02:25:42.679309Z","shell.execute_reply.started":"2022-03-16T02:25:42.37582Z"},"trusted":true},"outputs":[],"source":["network_input, network_output = prepare_sequences(notes, durations, lookups, distincts, seq_len)"]},{"cell_type":"markdown","metadata":{},"source":["Divide the dataset by 32 notes to create the training set. Target is the next pitch and time signature in the sequence."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.681358Z","iopub.status.busy":"2022-03-16T02:25:42.681143Z","iopub.status.idle":"2022-03-16T02:25:42.691883Z","shell.execute_reply":"2022-03-16T02:25:42.690977Z","shell.execute_reply.started":"2022-03-16T02:25:42.681333Z"},"trusted":true},"outputs":[],"source":["print('pitch input')\n","print(network_input[0][0])\n","print('duration input')\n","print(network_input[1][0])\n","print('pitch target')\n","print(network_output[0][0])\n","print('duration target')\n","print(network_output[1][0])"]},{"cell_type":"markdown","metadata":{},"source":["----------------------------------\n","# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.693232Z","iopub.status.busy":"2022-03-16T02:25:42.693012Z","iopub.status.idle":"2022-03-16T02:25:43.437212Z","shell.execute_reply":"2022-03-16T02:25:43.436379Z","shell.execute_reply.started":"2022-03-16T02:25:42.693206Z"},"trusted":true},"outputs":[],"source":["model, att_model = create_network(n_notes, n_durations, embed_size, rnn_units, use_attention)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:43.438506Z","iopub.status.busy":"2022-03-16T02:25:43.438305Z","iopub.status.idle":"2022-03-16T02:25:44.400898Z","shell.execute_reply":"2022-03-16T02:25:44.399767Z","shell.execute_reply.started":"2022-03-16T02:25:43.43848Z"},"trusted":true},"outputs":[],"source":["plot_model(model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)"]},{"cell_type":"markdown","metadata":{},"source":["---------------------------------------------\n","# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-03-16T02:25:44.402821Z","iopub.status.busy":"2022-03-16T02:25:44.402534Z","iopub.status.idle":"2022-03-16T03:02:11.727564Z","shell.execute_reply":"2022-03-16T03:02:11.726756Z","shell.execute_reply.started":"2022-03-16T02:25:44.402771Z"},"trusted":true},"outputs":[],"source":["weights_folder = os.path.join(run_folder, 'weights')\n","\n","checkpoint1 = ModelCheckpoint(\n","    os.path.join(weights_folder, \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.h5\"),\n","    monitor='loss',\n","    verbose=0,\n","    save_best_only=True,\n","    mode='min'\n",")\n","\n","checkpoint2 = ModelCheckpoint(\n","    os.path.join(weights_folder, \"weights.h5\"),\n","    monitor='loss',\n","    verbose=0,\n","    save_best_only=True,\n","    mode='min'\n",")\n","\n","early_stopping = EarlyStopping(\n","    monitor='loss'\n","    , restore_best_weights=True\n","    , patience = 10\n",")\n","\n","\n","callbacks_list = [\n","    checkpoint1\n","    , checkpoint2\n","    , early_stopping\n"," ]\n","\n","model.save_weights(os.path.join(weights_folder, \"weights.h5\"))\n","model.fit(network_input, network_output\n","          , epochs=2000000, batch_size=32\n","          , validation_split = 0.2\n","          , callbacks=callbacks_list\n","          , shuffle=True\n","         )"]},{"cell_type":"markdown","metadata":{},"source":["----------------------------------------\n","# Predicting"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:11.72986Z","iopub.status.busy":"2022-03-16T03:02:11.729365Z","iopub.status.idle":"2022-03-16T03:02:11.740723Z","shell.execute_reply":"2022-03-16T03:02:11.739775Z","shell.execute_reply.started":"2022-03-16T03:02:11.729829Z"},"trusted":true},"outputs":[],"source":["# prediction params\n","notes_temp=0.5\n","duration_temp = 0.5\n","max_extra_notes = 50\n","max_seq_len = 32\n","seq_len = 32\n","\n","notes = ['START']\n","durations = [0]\n","\n","if seq_len is not None:\n","    notes = ['START'] * (seq_len - len(notes)) + notes\n","    durations = [0] * (seq_len - len(durations)) + durations\n","\n","sequence_length = len(notes)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:11.742766Z","iopub.status.busy":"2022-03-16T03:02:11.742548Z","iopub.status.idle":"2022-03-16T03:02:23.672571Z","shell.execute_reply":"2022-03-16T03:02:23.671672Z","shell.execute_reply.started":"2022-03-16T03:02:11.742739Z"},"trusted":true},"outputs":[],"source":["prediction_output = []\n","notes_input_sequence = []\n","durations_input_sequence = []\n","overall_preds = []\n","\n","for n, d in zip(notes,durations):\n","    note_int = note_to_int[n]\n","    duration_int = duration_to_int[d]\n","    \n","    notes_input_sequence.append(note_int)\n","    durations_input_sequence.append(duration_int)\n","    \n","    prediction_output.append([n, d])\n","    \n","    if n != 'START':\n","        midi_note = note.Note(n)\n","        new_note = np.zeros(128)\n","        new_note[midi_note.pitch.midi] = 1\n","        overall_preds.append(new_note)\n","\n","att_matrix = np.zeros(shape = (max_extra_notes+sequence_length, max_extra_notes))\n","\n","for note_index in range(max_extra_notes):\n","\n","    prediction_input = [\n","        np.array([notes_input_sequence])\n","        , np.array([durations_input_sequence])\n","       ]\n","\n","    notes_prediction, durations_prediction = model.predict(prediction_input, verbose=0)\n","    if use_attention:\n","        att_prediction = att_model.predict(prediction_input, verbose=0)[0]\n","        att_matrix[(note_index-len(att_prediction)+sequence_length):(note_index+sequence_length), note_index] = att_prediction\n","    \n","    new_note = np.zeros(128)\n","    \n","    for idx, n_i in enumerate(notes_prediction[0]):\n","        try:\n","            note_name = int_to_note[idx]\n","            midi_note = note.Note(note_name)\n","            new_note[midi_note.pitch.midi] = n_i            \n","        except:\n","            pass\n","        \n","    overall_preds.append(new_note)            \n","    \n","    i1 = sample_with_temp(notes_prediction[0], notes_temp)\n","    i2 = sample_with_temp(durations_prediction[0], duration_temp)    \n","\n","    note_result = int_to_note[i1]\n","    duration_result = int_to_duration[i2]\n","    \n","    prediction_output.append([note_result, duration_result])\n","\n","    notes_input_sequence.append(i1)\n","    durations_input_sequence.append(i2)\n","    \n","    if len(notes_input_sequence) > max_seq_len:\n","        notes_input_sequence = notes_input_sequence[1:]\n","        durations_input_sequence = durations_input_sequence[1:]\n","        \n","    if note_result == 'START':\n","        break\n","\n","overall_preds = np.transpose(np.array(overall_preds)) \n","print('Generated sequence of {} notes'.format(len(prediction_output)))"]},{"cell_type":"markdown","metadata":{},"source":["---------------------------------------\n","# Intrepreting Model"]},{"cell_type":"markdown","metadata":{},"source":["-------------------------------------------\n","## Heatmap"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:29:35.525069Z","iopub.status.busy":"2022-03-16T03:29:35.52443Z","iopub.status.idle":"2022-03-16T03:29:36.436508Z","shell.execute_reply":"2022-03-16T03:29:36.435568Z","shell.execute_reply.started":"2022-03-16T03:29:35.525017Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(15,15))\n","ax.set_yticks([int(j) for j in range(35,70)])\n","plt.imshow(overall_preds[35:70,:], origin=\"lower\", cmap='coolwarm', vmin = -0.5, vmax = 0.5, extent=[0, max_extra_notes, 35,70])\n","plt.xlabel(\"Note number\",fontsize=20)\n","plt.ylabel(\"Pitch value (MIDI number)\",fontsize=20)\n","plt.title(\"Probability distribution of the next possible note over time\",fontsize=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:24.634201Z","iopub.status.busy":"2022-03-16T03:02:24.633955Z","iopub.status.idle":"2022-03-16T03:02:24.843924Z","shell.execute_reply":"2022-03-16T03:02:24.843343Z","shell.execute_reply.started":"2022-03-16T03:02:24.634164Z"},"trusted":true},"outputs":[],"source":["output_folder = os.path.join(run_folder, 'output')\n","\n","midi_stream = stream.Stream()\n","\n","# create note and chord objects based on the values generated by the model\n","for pattern in prediction_output:\n","    note_pattern, duration_pattern = pattern\n","    # pattern is a chord\n","    if ('.' in note_pattern):\n","        notes_in_chord = note_pattern.split('.')\n","        chord_notes = []\n","        for current_note in notes_in_chord:\n","            new_note = note.Note(current_note)\n","            new_note.duration = duration.Duration(duration_pattern)\n","            new_note.storedInstrument = instrument.Violoncello()\n","            chord_notes.append(new_note)\n","        new_chord = chord.Chord(chord_notes)\n","        midi_stream.append(new_chord)\n","    elif note_pattern == 'rest':\n","    # pattern is a rest\n","        new_note = note.Rest()\n","        new_note.duration = duration.Duration(duration_pattern)\n","        new_note.storedInstrument = instrument.Violoncello()\n","        midi_stream.append(new_note)\n","    elif note_pattern != 'START':\n","    # pattern is a note\n","        new_note = note.Note(note_pattern)\n","        new_note.duration = duration.Duration(duration_pattern)\n","        new_note.storedInstrument = instrument.Violoncello()\n","        midi_stream.append(new_note)\n","\n","midi_stream = midi_stream.chordify()\n","timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n","new_file = 'output-' + timestr + '.mid'\n","midi_stream.write('midi', fp=os.path.join(output_folder, new_file))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:24.845595Z","iopub.status.busy":"2022-03-16T03:02:24.844868Z","iopub.status.idle":"2022-03-16T03:02:31.864417Z","shell.execute_reply":"2022-03-16T03:02:31.863342Z","shell.execute_reply.started":"2022-03-16T03:02:24.845562Z"},"trusted":true},"outputs":[],"source":["new_path = '/kaggle/working/output/'+new_file\n","fs = FluidSynth()\n","fs.midi_to_audio(new_path, 'new_output.wav')"]},{"cell_type":"markdown","metadata":{},"source":["---------------------------------------\n","## Attention\n","\n","![](https://miro.medium.com/max/1400/1*2dLzmSops3jTvTR1wzRX0w.gif)\n","Picture Credit: https://miro.medium.com\n","\n","In order to determine which notes or sequence of notes may follow a particular passage, it is important to use earlier information far back in the sequence, not the most recent information. A good way to solve this problem is attention. In the attention mechanism, the model builds a context vector by weighting the hidden states in the previous time step of the encoder RNN. The attention mechanism is a set of layers that transforms the encoder's previous and current hidden states into additive weights for context vector generation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:48:41.808438Z","iopub.status.busy":"2022-03-16T03:48:41.8081Z","iopub.status.idle":"2022-03-16T03:48:45.149716Z","shell.execute_reply":"2022-03-16T03:48:45.149005Z","shell.execute_reply.started":"2022-03-16T03:48:41.808407Z"},"trusted":true},"outputs":[],"source":["if use_attention:\n","    fig, ax = plt.subplots(figsize=(20,20))\n","    im = ax.imshow(att_matrix[(seq_len-2):,], cmap='coolwarm', interpolation='nearest')    \n","\n","    # Minor ticks\n","    ax.set_xticks(np.arange(-.5, len(prediction_output)- seq_len, 1), minor=True);\n","    ax.set_yticks(np.arange(-.5, len(prediction_output)- seq_len, 1), minor=True);\n","\n","    # Gridlines based on minor ticks\n","    ax.grid(which='minor', color='black', linestyle='-', linewidth=1)    \n","    \n","    # We want to show all ticks...\n","    ax.set_xticks(np.arange(len(prediction_output) - seq_len))\n","    ax.set_yticks(np.arange(len(prediction_output)- seq_len+2))\n","    # ... and label them with the respective list entries\n","    ax.set_xticklabels([n[0] for n in prediction_output[(seq_len):]])\n","    ax.set_yticklabels([n[0] for n in prediction_output[(seq_len - 2):]])\n","    ax.xaxis.tick_top()    \n","    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"left\", va = \"center\", rotation_mode=\"anchor\")\n","    plt.xlabel(\"sequence of generated notes\",fontsize=20)\n","    plt.ylabel(\"The point of attention\",fontsize=20)\n","    plt.title(\"The amount of attention given to the network hidden state\",fontsize=30)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["The attention mechanism helps the network determine which of the previous states of the circulating layer is important for successive sequence prediction. The encoder-decoder network predicts the note sequence using the RNN decoder, rather than creating a sequence one note at a time."]},{"cell_type":"markdown","metadata":{},"source":["-----------------------------------\n","# Let's compare the original performance with the new one."]},{"cell_type":"markdown","metadata":{},"source":["---------------------------------------\n","## Let's listen originals"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:35.705582Z","iopub.status.busy":"2022-03-16T03:02:35.702732Z","iopub.status.idle":"2022-03-16T03:02:38.784404Z","shell.execute_reply":"2022-03-16T03:02:38.783252Z","shell.execute_reply.started":"2022-03-16T03:02:35.705322Z"},"trusted":true},"outputs":[],"source":["IPython.display.Audio(\"bach_846.wav\") "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:38.788466Z","iopub.status.busy":"2022-03-16T03:02:38.788053Z","iopub.status.idle":"2022-03-16T03:02:40.733019Z","shell.execute_reply":"2022-03-16T03:02:40.728941Z","shell.execute_reply.started":"2022-03-16T03:02:38.788424Z"},"trusted":true},"outputs":[],"source":["IPython.display.Audio(\"bach_847.wav\") "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:40.742871Z","iopub.status.busy":"2022-03-16T03:02:40.738779Z","iopub.status.idle":"2022-03-16T03:02:42.404939Z","shell.execute_reply":"2022-03-16T03:02:42.399907Z","shell.execute_reply.started":"2022-03-16T03:02:40.742618Z"},"trusted":true},"outputs":[],"source":["IPython.display.Audio(\"bach_850.wav\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:42.411329Z","iopub.status.busy":"2022-03-16T03:02:42.41017Z","iopub.status.idle":"2022-03-16T03:02:57.306915Z","shell.execute_reply":"2022-03-16T03:02:57.305912Z","shell.execute_reply.started":"2022-03-16T03:02:42.411205Z"},"trusted":true},"outputs":[],"source":["original_score.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:57.309097Z","iopub.status.busy":"2022-03-16T03:02:57.308825Z","iopub.status.idle":"2022-03-16T03:02:57.43576Z","shell.execute_reply":"2022-03-16T03:02:57.434865Z","shell.execute_reply.started":"2022-03-16T03:02:57.309065Z"},"trusted":true},"outputs":[],"source":["new_score = converter.parse(new_path).chordify()"]},{"cell_type":"markdown","metadata":{},"source":["-------------------------------\n","## Newly composed music\n","\n","Finally, let's listen to the music we made with our model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:57.437716Z","iopub.status.busy":"2022-03-16T03:02:57.437236Z","iopub.status.idle":"2022-03-16T03:02:57.473984Z","shell.execute_reply":"2022-03-16T03:02:57.472765Z","shell.execute_reply.started":"2022-03-16T03:02:57.437671Z"},"trusted":true},"outputs":[],"source":["IPython.display.Audio(\"new_output.wav\") "]},{"cell_type":"markdown","metadata":{},"source":["Wow! Very interesting music was made. It is similar to the previous three songs, but something is different."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:57.475791Z","iopub.status.busy":"2022-03-16T03:02:57.475394Z","iopub.status.idle":"2022-03-16T03:02:58.103502Z","shell.execute_reply":"2022-03-16T03:02:58.102826Z","shell.execute_reply.started":"2022-03-16T03:02:57.475749Z"},"trusted":true},"outputs":[],"source":["new_score.show()"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"border: solid 3px blue;\">"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
