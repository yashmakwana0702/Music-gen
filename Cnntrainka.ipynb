{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-03-16T02:22:29.654844Z","iopub.status.busy":"2022-03-16T02:22:29.653337Z","iopub.status.idle":"2022-03-16T02:23:43.207708Z","shell.execute_reply":"2022-03-16T02:23:43.206425Z","shell.execute_reply.started":"2022-03-16T02:22:29.654551Z"},"trusted":true},"outputs":[],"source":["try:\n","    import music21\n","except:\n","    ! pip install music21\n","    ! sudo apt install musescore3 -y"]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-03-16T02:23:43.210985Z","iopub.status.busy":"2022-03-16T02:23:43.210673Z","iopub.status.idle":"2022-03-16T02:24:18.549182Z","shell.execute_reply":"2022-03-16T02:24:18.548232Z","shell.execute_reply.started":"2022-03-16T02:23:43.210941Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting midi2audio\n","  Downloading midi2audio-0.1.1-py2.py3-none-any.whl (8.7 kB)\n","Installing collected packages: midi2audio\n","Successfully installed midi2audio-0.1.1\n","[sudo] password for yash: \n"]}],"source":["try:\n","    import midi2audio\n","except:\n","    ! pip install midi2audio\n","    ! sudo apt-get install fluidsynth -y"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 8424080696292412935\n","xla_global_id: -1\n","]\n"]},{"name":"stderr","output_type":"stream","text":["2022-04-02 09:52:28.437885: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-04-02 09:52:28.553193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-04-02 09:52:28.563885: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n","2022-04-02 09:52:28.563944: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n"]}],"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())\n"]},{"cell_type":"markdown","metadata":{},"source":["Creating something new is a difficult task. Creation does not start from nothing.\n","Perhaps it is finding something new on a well-established foundation.\n","From this perspective, we will be able to create new music through our model.\n","\n","In this notebook, we will learn bach's music through RNN and attention and use it to create new music."]},{"cell_type":"markdown","metadata":{},"source":["--------------------------\n","# Setting Up"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:29:09.369576Z","iopub.status.busy":"2022-03-16T03:29:09.369229Z","iopub.status.idle":"2022-03-16T03:29:10.073884Z","shell.execute_reply":"2022-03-16T03:29:10.073055Z","shell.execute_reply.started":"2022-03-16T03:29:09.369545Z"},"trusted":true},"outputs":[],"source":["import IPython\n","from IPython.display import Image, Audio\n","from midi2audio import FluidSynth\n","from music21 import corpus, converter, instrument, note, stream, chord, duration\n","import matplotlib.pyplot as plt\n","import time\n","\n","import os\n","import pickle\n","import keras\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.utils.vis_utils import plot_model\n","\n","import os\n","import numpy as np\n","import glob\n","\n","from keras.layers import LSTM, Input, Dropout, Dense, Activation, Embedding, Concatenate, Reshape\n","from keras.layers import Flatten, RepeatVector, Permute, TimeDistributed\n","from keras.layers import Multiply, Lambda, Softmax\n","import keras.backend as K \n","from keras.models import Model\n","from tensorflow.keras.optimizers import RMSprop\n","\n","from keras.utils import np_utils\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{},"source":["**Chordify Method:**\n","> Chordify is a madeup word that we created in music21 for the process of making chords out of non-chords. Chordify powerful tool for reducing a complex score with multiple parts to a succession of chords in one part that represent everything that is happening in the score. \n","\n","Ref: https://web.mit.edu/music21/doc/usersGuide"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:24:24.936781Z","iopub.status.busy":"2022-03-16T02:24:24.936063Z","iopub.status.idle":"2022-03-16T02:24:31.830087Z","shell.execute_reply":"2022-03-16T02:24:31.829206Z","shell.execute_reply.started":"2022-03-16T02:24:24.936732Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"Cannot find file in ../input/classical-music-midi/bach/bach_846.mid","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mf:\\Music-gen\\Cnntrainka.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000007?line=1'>2</a>\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbach_846\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000007?line=2'>3</a>\u001b[0m file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.mid\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(dataset_name, filename)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000007?line=4'>5</a>\u001b[0m original_score \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39;49mparse(file)\u001b[39m.\u001b[39mchordify()\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\music21\\converter\\__init__.py:1183\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(value, *args, **keywords)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/music21/converter/__init__.py?line=1179'>1180</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCannot find file in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(value)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/music21/converter/__init__.py?line=1180'>1181</a>\u001b[0m \u001b[39melif\u001b[39;00m (\u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m common\u001b[39m.\u001b[39mfindFormatFile(value) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/music21/converter/__init__.py?line=1181'>1182</a>\u001b[0m     \u001b[39m# assume mistyped file path\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/music21/converter/__init__.py?line=1182'>1183</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCannot find file in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(value)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/music21/converter/__init__.py?line=1183'>1184</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/music21/converter/__init__.py?line=1184'>1185</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parseData(value, number\u001b[39m=\u001b[39mnumber, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39mm21Format, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkeywords)\n","\u001b[1;31mFileNotFoundError\u001b[0m: Cannot find file in ../input/classical-music-midi/bach/bach_846.mid"]}],"source":["dataset_name = '../input/classical-music-midi/bach'\n","filename = 'bach_846'\n","file = \"{}/{}.mid\".format(dataset_name, filename)\n","\n","original_score = converter.parse(file).chordify()"]},{"cell_type":"markdown","metadata":{},"source":["**Let's listen to the three performances of bach first.**"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2022-03-16T02:24:31.833094Z","iopub.status.busy":"2022-03-16T02:24:31.832743Z","iopub.status.idle":"2022-03-16T02:24:45.971576Z","shell.execute_reply":"2022-03-16T02:24:45.970622Z","shell.execute_reply.started":"2022-03-16T02:24:31.833058Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[WinError 2] The system cannot find the file specified","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mf:\\Music-gen\\Cnntrainka.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000009?line=0'>1</a>\u001b[0m fs \u001b[39m=\u001b[39m FluidSynth()\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000009?line=1'>2</a>\u001b[0m file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../input/classical-music-midi/bach/bach_846.mid\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000009?line=2'>3</a>\u001b[0m fs\u001b[39m.\u001b[39;49mmidi_to_audio(file, \u001b[39m'\u001b[39;49m\u001b[39mbach_846.wav\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000009?line=3'>4</a>\u001b[0m IPython\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mAudio(\u001b[39m\"\u001b[39m\u001b[39mbach_846.wav\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\midi2audio.py:46\u001b[0m, in \u001b[0;36mFluidSynth.midi_to_audio\u001b[1;34m(self, midi_file, audio_file)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/midi2audio.py?line=44'>45</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmidi_to_audio\u001b[39m(\u001b[39mself\u001b[39m, midi_file, audio_file):\n\u001b[1;32m---> <a href='file:///c%3A/Users/yashm/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/midi2audio.py?line=45'>46</a>\u001b[0m     subprocess\u001b[39m.\u001b[39;49mcall([\u001b[39m'\u001b[39;49m\u001b[39mfluidsynth\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m-ni\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msound_font, midi_file, \u001b[39m'\u001b[39;49m\u001b[39m-F\u001b[39;49m\u001b[39m'\u001b[39;49m, audio_file, \u001b[39m'\u001b[39;49m\u001b[39m-r\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_rate)])\n","File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py:349\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=340'>341</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39m*\u001b[39mpopenargs, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=341'>342</a>\u001b[0m     \u001b[39m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=342'>343</a>\u001b[0m \u001b[39m    timeout, then return the returncode attribute.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=343'>344</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=346'>347</a>\u001b[0m \u001b[39m    retcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=347'>348</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=348'>349</a>\u001b[0m     \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=349'>350</a>\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=350'>351</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m p\u001b[39m.\u001b[39mwait(timeout\u001b[39m=\u001b[39mtimeout)\n","File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=946'>947</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=947'>948</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=948'>949</a>\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=950'>951</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=951'>952</a>\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=952'>953</a>\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=953'>954</a>\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=954'>955</a>\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=955'>956</a>\u001b[0m                         errread, errwrite,\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=956'>957</a>\u001b[0m                         restore_signals,\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=957'>958</a>\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=958'>959</a>\u001b[0m                         start_new_session)\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=959'>960</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=960'>961</a>\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=961'>962</a>\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n","File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py:1420\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1417'>1418</a>\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1418'>1419</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1419'>1420</a>\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1420'>1421</a>\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1421'>1422</a>\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1422'>1423</a>\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1423'>1424</a>\u001b[0m                              creationflags,\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1424'>1425</a>\u001b[0m                              env,\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1425'>1426</a>\u001b[0m                              cwd,\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1426'>1427</a>\u001b[0m                              startupinfo)\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1427'>1428</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1428'>1429</a>\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1429'>1430</a>\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1432'>1433</a>\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1433'>1434</a>\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1434'>1435</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1435'>1436</a>\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.9_3.9.3312.0_x64__qbz5n2kfra8p0/lib/subprocess.py?line=1436'>1437</a>\u001b[0m                          errread, errwrite)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"]}],"source":["fs = FluidSynth()\n","file = '../input/classical-music-midi/bach/bach_846.mid'\n","fs.midi_to_audio(file, 'bach_846.wav')\n","IPython.display.Audio(\"bach_846.wav\") "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:24:45.973317Z","iopub.status.busy":"2022-03-16T02:24:45.973039Z","iopub.status.idle":"2022-03-16T02:24:58.929719Z","shell.execute_reply":"2022-03-16T02:24:58.928911Z","shell.execute_reply.started":"2022-03-16T02:24:45.973287Z"},"trusted":true},"outputs":[],"source":["fs.midi_to_audio('../input/classical-music-midi/bach/bach_847.mid', 'bach_847.wav')\n","IPython.display.Audio(\"bach_847.wav\") "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:24:58.931557Z","iopub.status.busy":"2022-03-16T02:24:58.931219Z","iopub.status.idle":"2022-03-16T02:25:10.560738Z","shell.execute_reply":"2022-03-16T02:25:10.559578Z","shell.execute_reply.started":"2022-03-16T02:24:58.931529Z"},"trusted":true},"outputs":[],"source":["fs.midi_to_audio('../input/classical-music-midi/bach/bach_850.mid', 'bach_850.wav')\n","IPython.display.Audio(\"bach_850.wav\") "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:10.562547Z","iopub.status.busy":"2022-03-16T02:25:10.562304Z","iopub.status.idle":"2022-03-16T02:25:21.152833Z","shell.execute_reply":"2022-03-16T02:25:21.151866Z","shell.execute_reply.started":"2022-03-16T02:25:10.562518Z"},"trusted":true},"outputs":[],"source":["original_score.show()"]},{"cell_type":"markdown","metadata":{},"source":["---------------------\n","# Extracting the data\n","\n","It loops through the score and extracts the pitch and time of each note (and rest) into two lists. The entire chord is stored as a string, and individual notes in the chord are separated by dots. The male after the name of each note refers to the octave to which the note belongs."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:21.203615Z","iopub.status.busy":"2022-03-16T02:25:21.202862Z","iopub.status.idle":"2022-03-16T02:25:21.261033Z","shell.execute_reply":"2022-03-16T02:25:21.260281Z","shell.execute_reply.started":"2022-03-16T02:25:21.203567Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'original_score' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mf:\\Music-gen\\Cnntrainka.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000014?line=0'>1</a>\u001b[0m notes \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000014?line=1'>2</a>\u001b[0m durations \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000014?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m original_score\u001b[39m.\u001b[39mflat:    \n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000014?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(element, chord\u001b[39m.\u001b[39mChord):\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Music-gen/Cnntrainka.ipynb#ch0000014?line=5'>6</a>\u001b[0m         notes\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(n\u001b[39m.\u001b[39mnameWithOctave \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m element\u001b[39m.\u001b[39mpitches))\n","\u001b[1;31mNameError\u001b[0m: name 'original_score' is not defined"]}],"source":["notes = []\n","durations = []\n","\n","for element in original_score.flat:    \n","    if isinstance(element, chord.Chord):\n","        notes.append('.'.join(n.nameWithOctave for n in element.pitches))\n","        durations.append(element.duration.quarterLength)\n","\n","    if isinstance(element, note.Note):\n","        if element.isRest:\n","            notes.append(str(element.name))\n","            durations.append(element.duration.quarterLength)\n","        else:\n","            notes.append(str(element.nameWithOctave))\n","            durations.append(element.duration.quarterLength)   "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:21.263038Z","iopub.status.busy":"2022-03-16T02:25:21.262508Z","iopub.status.idle":"2022-03-16T02:25:21.288859Z","shell.execute_reply":"2022-03-16T02:25:21.287969Z","shell.execute_reply.started":"2022-03-16T02:25:21.262996Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","duration pitch\n"]}],"source":["print('\\nduration', 'pitch')\n","idx = 0\n","for n,d in zip(notes,durations):\n","    if idx < 50:\n","        print(d, '\\t', n)\n","    idx = idx + 1   "]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"border: solid 3px blue;\">\n","\n","# Creating Music\n","\n","Here, modeling is done using RNN and atension mechanism, and a new music is composed using this."]},{"cell_type":"markdown","metadata":{},"source":["## Defiing Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:21.290775Z","iopub.status.busy":"2022-03-16T02:25:21.290447Z","iopub.status.idle":"2022-03-16T02:25:21.319037Z","shell.execute_reply":"2022-03-16T02:25:21.318017Z","shell.execute_reply.started":"2022-03-16T02:25:21.29074Z"},"trusted":true},"outputs":[],"source":["def get_music_list(data_folder):    \n","    file_list = glob.glob(os.path.join(data_folder, \"*.mid\"))\n","    parser = converter    \n","    return file_list, parser\n","\n","def create_network(n_notes, n_durations, embed_size = 100, rnn_units = 256, use_attention = False):\n","    notes_in = Input(shape = (None,))\n","    durations_in = Input(shape = (None,))\n","\n","    x1 = Embedding(n_notes, embed_size)(notes_in)\n","    x2 = Embedding(n_durations, embed_size)(durations_in) \n","    x = Concatenate()([x1,x2])\n","    x = LSTM(rnn_units, return_sequences=True)(x)\n","\n","    if use_attention:\n","        x = LSTM(rnn_units, return_sequences=True)(x)\n","        e = Dense(1, activation='tanh')(x)\n","        e = Reshape([-1])(e)\n","        alpha = Activation('softmax')(e)\n","        alpha_repeated = Permute([2, 1])(RepeatVector(rnn_units)(alpha))\n","        c = Multiply()([x, alpha_repeated])\n","        c = Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(rnn_units,))(c)    \n","    else:\n","        c = LSTM(rnn_units)(x)\n","                                    \n","    notes_out = Dense(n_notes, activation = 'softmax', name = 'pitch')(c)\n","    durations_out = Dense(n_durations, activation = 'softmax', name = 'duration')(c)\n","   \n","    model = Model([notes_in, durations_in], [notes_out, durations_out])    \n","\n","    if use_attention:\n","        att_model = Model([notes_in, durations_in], alpha)\n","    else:\n","        att_model = None\n","        \n","    opti = RMSprop(lr = 0.001)\n","    model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy'], optimizer=opti)\n","\n","    return model, att_model\n","\n","\n","def get_distinct(elements):\n","    # Get all pitch names\n","    element_names = sorted(set(elements))\n","    n_elements = len(element_names)\n","    return (element_names, n_elements)\n","\n","def create_lookups(element_names):\n","    # create dictionary to map notes and durations to integers\n","    element_to_int = dict((element, number) for number, element in enumerate(element_names))\n","    int_to_element = dict((number, element) for number, element in enumerate(element_names))\n","    return (element_to_int, int_to_element)    \n","\n","def prepare_sequences(notes, durations, lookups, distincts, seq_len =32):\n","    note_to_int, int_to_note, duration_to_int, int_to_duration = lookups\n","    note_names, n_notes, duration_names, n_durations = distincts\n","\n","    notes_network_input = []\n","    notes_network_output = []\n","    durations_network_input = []\n","    durations_network_output = []\n","\n","    # create input sequences and the corresponding outputs\n","    for i in range(len(notes) - seq_len):\n","        notes_sequence_in = notes[i:i + seq_len]\n","        notes_sequence_out = notes[i + seq_len]\n","        notes_network_input.append([note_to_int[char] for char in notes_sequence_in])\n","        notes_network_output.append(note_to_int[notes_sequence_out])\n","\n","        durations_sequence_in = durations[i:i + seq_len]\n","        durations_sequence_out = durations[i + seq_len]\n","        durations_network_input.append([duration_to_int[char] for char in durations_sequence_in])\n","        durations_network_output.append(duration_to_int[durations_sequence_out])\n","\n","    n_patterns = len(notes_network_input)\n","\n","    # reshape the input into a format compatible with LSTM layers\n","    notes_network_input = np.reshape(notes_network_input, (n_patterns, seq_len))\n","    durations_network_input = np.reshape(durations_network_input, (n_patterns, seq_len))\n","    network_input = [notes_network_input, durations_network_input]\n","\n","    notes_network_output = np_utils.to_categorical(notes_network_output, num_classes=n_notes)\n","    durations_network_output = np_utils.to_categorical(durations_network_output, num_classes=n_durations)\n","    network_output = [notes_network_output, durations_network_output]\n","    return (network_input, network_output)\n","\n","def sample_with_temp(preds, temperature):\n","    if temperature == 0:\n","        return np.argmax(preds)\n","    else:\n","        preds = np.log(preds) / temperature\n","        exp_preds = np.exp(preds)\n","        preds = exp_preds / np.sum(exp_preds)\n","        return np.random.choice(len(preds), p=preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:21.320869Z","iopub.status.busy":"2022-03-16T02:25:21.320618Z","iopub.status.idle":"2022-03-16T02:25:21.335196Z","shell.execute_reply":"2022-03-16T02:25:21.334395Z","shell.execute_reply.started":"2022-03-16T02:25:21.32084Z"},"trusted":true},"outputs":[],"source":["# run params\n","run_folder = '/kaggle/working'\n","\n","store_folder = os.path.join(run_folder, 'store')\n","data_folder ='../input/classical-music-midi/bach'\n","\n","if not os.path.exists('store'):\n","    os.mkdir(os.path.join(run_folder, 'store'))\n","    os.mkdir(os.path.join(run_folder, 'output'))\n","    os.mkdir(os.path.join(run_folder, 'weights'))\n","    os.mkdir(os.path.join(run_folder, 'viz'))\n","\n","mode = 'build'\n","\n","# data params\n","intervals = range(1)\n","seq_len = 32\n","\n","# model params\n","embed_size = 100\n","rnn_units = 256\n","use_attention = True"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-03-16T02:25:21.339458Z","iopub.status.busy":"2022-03-16T02:25:21.339234Z","iopub.status.idle":"2022-03-16T02:25:42.333117Z","shell.execute_reply":"2022-03-16T02:25:42.332393Z","shell.execute_reply.started":"2022-03-16T02:25:21.33943Z"},"trusted":true},"outputs":[],"source":["if mode == 'build':    \n","    music_list, parser = get_music_list(data_folder)\n","    print(len(music_list), 'files in total')\n","\n","    notes = []\n","    durations = []\n","\n","    for i, file in enumerate(music_list):\n","        print(i+1, \"Parsing %s\" % file)\n","        print(file)\n","        original_score = parser.parse(file).chordify()        \n","        for interval in intervals:\n","            score = original_score.transpose(interval)\n","\n","            notes.extend(['START'] * seq_len)\n","            durations.extend([0]* seq_len)\n","\n","            for element in score.flat:                \n","                if isinstance(element, note.Note):\n","                    if element.isRest:\n","                        notes.append(str(element.name))\n","                        durations.append(element.duration.quarterLength)\n","                    else:\n","                        notes.append(str(element.nameWithOctave))\n","                        durations.append(element.duration.quarterLength)\n","                        \n","                if isinstance(element, chord.Chord):\n","                    notes.append('.'.join(n.nameWithOctave for n in element.pitches))\n","                    durations.append(element.duration.quarterLength)\n","\n","    with open(os.path.join(store_folder, 'notes'), 'wb') as f:\n","        pickle.dump(notes, f) \n","    with open(os.path.join(store_folder, 'durations'), 'wb') as f:\n","        pickle.dump(durations, f) \n","else:\n","    with open(os.path.join(store_folder, 'notes'), 'rb') as f:\n","        notes = pickle.load(f)\n","    with open(os.path.join(store_folder, 'durations'), 'rb') as f:\n","        durations = pickle.load(f) "]},{"cell_type":"markdown","metadata":{},"source":["------------------------------------------\n","# Embedding Note and Duration\n","\n","To create a dataset for training the model, we first convert the pitch and tempo into integer values. It doesn't matter what these values are because we use an embedding layer to convert the integer to a vector."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.334363Z","iopub.status.busy":"2022-03-16T02:25:42.334175Z","iopub.status.idle":"2022-03-16T02:25:42.352485Z","shell.execute_reply":"2022-03-16T02:25:42.351542Z","shell.execute_reply.started":"2022-03-16T02:25:42.33434Z"},"trusted":true},"outputs":[],"source":["# get the distinct sets of notes and durations\n","note_names, n_notes = get_distinct(notes)\n","duration_names, n_durations = get_distinct(durations)\n","distincts = [note_names, n_notes, duration_names, n_durations]\n","\n","with open(os.path.join(store_folder, 'distincts'), 'wb') as f:\n","    pickle.dump(distincts, f)\n","\n","# make the lookup dictionaries for notes and dictionaries and save\n","note_to_int, int_to_note = create_lookups(note_names)\n","duration_to_int, int_to_duration = create_lookups(duration_names)\n","lookups = [note_to_int, int_to_note, duration_to_int, int_to_duration]\n","\n","with open(os.path.join(store_folder, 'lookups'), 'wb') as f:\n","    pickle.dump(lookups, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.354609Z","iopub.status.busy":"2022-03-16T02:25:42.354298Z","iopub.status.idle":"2022-03-16T02:25:42.363124Z","shell.execute_reply":"2022-03-16T02:25:42.362388Z","shell.execute_reply.started":"2022-03-16T02:25:42.354569Z"},"trusted":true},"outputs":[],"source":["print('\\nnote_to_int')\n","for i, item in enumerate(note_to_int.items()):\n","    if i < 10:\n","        print(item)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.365081Z","iopub.status.busy":"2022-03-16T02:25:42.364494Z","iopub.status.idle":"2022-03-16T02:25:42.373721Z","shell.execute_reply":"2022-03-16T02:25:42.372962Z","shell.execute_reply.started":"2022-03-16T02:25:42.365038Z"},"trusted":true},"outputs":[],"source":["print('\\nduration_to_int')\n","duration_to_int"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.375862Z","iopub.status.busy":"2022-03-16T02:25:42.375111Z","iopub.status.idle":"2022-03-16T02:25:42.680043Z","shell.execute_reply":"2022-03-16T02:25:42.679309Z","shell.execute_reply.started":"2022-03-16T02:25:42.37582Z"},"trusted":true},"outputs":[],"source":["network_input, network_output = prepare_sequences(notes, durations, lookups, distincts, seq_len)"]},{"cell_type":"markdown","metadata":{},"source":["Divide the dataset by 32 notes to create the training set. Target is the next pitch and time signature in the sequence."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.681358Z","iopub.status.busy":"2022-03-16T02:25:42.681143Z","iopub.status.idle":"2022-03-16T02:25:42.691883Z","shell.execute_reply":"2022-03-16T02:25:42.690977Z","shell.execute_reply.started":"2022-03-16T02:25:42.681333Z"},"trusted":true},"outputs":[],"source":["print('pitch input')\n","print(network_input[0][0])\n","print('duration input')\n","print(network_input[1][0])\n","print('pitch target')\n","print(network_output[0][0])\n","print('duration target')\n","print(network_output[1][0])"]},{"cell_type":"markdown","metadata":{},"source":["----------------------------------\n","# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:42.693232Z","iopub.status.busy":"2022-03-16T02:25:42.693012Z","iopub.status.idle":"2022-03-16T02:25:43.437212Z","shell.execute_reply":"2022-03-16T02:25:43.436379Z","shell.execute_reply.started":"2022-03-16T02:25:42.693206Z"},"trusted":true},"outputs":[],"source":["model, att_model = create_network(n_notes, n_durations, embed_size, rnn_units, use_attention)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T02:25:43.438506Z","iopub.status.busy":"2022-03-16T02:25:43.438305Z","iopub.status.idle":"2022-03-16T02:25:44.400898Z","shell.execute_reply":"2022-03-16T02:25:44.399767Z","shell.execute_reply.started":"2022-03-16T02:25:43.43848Z"},"trusted":true},"outputs":[],"source":["plot_model(model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)"]},{"cell_type":"markdown","metadata":{},"source":["---------------------------------------------\n","# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-03-16T02:25:44.402821Z","iopub.status.busy":"2022-03-16T02:25:44.402534Z","iopub.status.idle":"2022-03-16T03:02:11.727564Z","shell.execute_reply":"2022-03-16T03:02:11.726756Z","shell.execute_reply.started":"2022-03-16T02:25:44.402771Z"},"trusted":true},"outputs":[],"source":["weights_folder = os.path.join(run_folder, 'weights')\n","\n","checkpoint1 = ModelCheckpoint(\n","    os.path.join(weights_folder, \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.h5\"),\n","    monitor='loss',\n","    verbose=0,\n","    save_best_only=True,\n","    mode='min'\n",")\n","\n","checkpoint2 = ModelCheckpoint(\n","    os.path.join(weights_folder, \"weights.h5\"),\n","    monitor='loss',\n","    verbose=0,\n","    save_best_only=True,\n","    mode='min'\n",")\n","\n","early_stopping = EarlyStopping(\n","    monitor='loss'\n","    , restore_best_weights=True\n","    , patience = 10\n",")\n","\n","\n","callbacks_list = [\n","    checkpoint1\n","    , checkpoint2\n","    , early_stopping\n"," ]\n","\n","model.save_weights(os.path.join(weights_folder, \"weights.h5\"))\n","model.fit(network_input, network_output\n","          , epochs=2000000, batch_size=32\n","          , validation_split = 0.2\n","          , callbacks=callbacks_list\n","          , shuffle=True\n","         )"]},{"cell_type":"markdown","metadata":{},"source":["----------------------------------------\n","# Predicting"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:11.72986Z","iopub.status.busy":"2022-03-16T03:02:11.729365Z","iopub.status.idle":"2022-03-16T03:02:11.740723Z","shell.execute_reply":"2022-03-16T03:02:11.739775Z","shell.execute_reply.started":"2022-03-16T03:02:11.729829Z"},"trusted":true},"outputs":[],"source":["# prediction params\n","notes_temp=0.5\n","duration_temp = 0.5\n","max_extra_notes = 50\n","max_seq_len = 32\n","seq_len = 32\n","\n","notes = ['START']\n","durations = [0]\n","\n","if seq_len is not None:\n","    notes = ['START'] * (seq_len - len(notes)) + notes\n","    durations = [0] * (seq_len - len(durations)) + durations\n","\n","sequence_length = len(notes)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:11.742766Z","iopub.status.busy":"2022-03-16T03:02:11.742548Z","iopub.status.idle":"2022-03-16T03:02:23.672571Z","shell.execute_reply":"2022-03-16T03:02:23.671672Z","shell.execute_reply.started":"2022-03-16T03:02:11.742739Z"},"trusted":true},"outputs":[],"source":["prediction_output = []\n","notes_input_sequence = []\n","durations_input_sequence = []\n","overall_preds = []\n","\n","for n, d in zip(notes,durations):\n","    note_int = note_to_int[n]\n","    duration_int = duration_to_int[d]\n","    \n","    notes_input_sequence.append(note_int)\n","    durations_input_sequence.append(duration_int)\n","    \n","    prediction_output.append([n, d])\n","    \n","    if n != 'START':\n","        midi_note = note.Note(n)\n","        new_note = np.zeros(128)\n","        new_note[midi_note.pitch.midi] = 1\n","        overall_preds.append(new_note)\n","\n","att_matrix = np.zeros(shape = (max_extra_notes+sequence_length, max_extra_notes))\n","\n","for note_index in range(max_extra_notes):\n","\n","    prediction_input = [\n","        np.array([notes_input_sequence])\n","        , np.array([durations_input_sequence])\n","       ]\n","\n","    notes_prediction, durations_prediction = model.predict(prediction_input, verbose=0)\n","    if use_attention:\n","        att_prediction = att_model.predict(prediction_input, verbose=0)[0]\n","        att_matrix[(note_index-len(att_prediction)+sequence_length):(note_index+sequence_length), note_index] = att_prediction\n","    \n","    new_note = np.zeros(128)\n","    \n","    for idx, n_i in enumerate(notes_prediction[0]):\n","        try:\n","            note_name = int_to_note[idx]\n","            midi_note = note.Note(note_name)\n","            new_note[midi_note.pitch.midi] = n_i            \n","        except:\n","            pass\n","        \n","    overall_preds.append(new_note)            \n","    \n","    i1 = sample_with_temp(notes_prediction[0], notes_temp)\n","    i2 = sample_with_temp(durations_prediction[0], duration_temp)    \n","\n","    note_result = int_to_note[i1]\n","    duration_result = int_to_duration[i2]\n","    \n","    prediction_output.append([note_result, duration_result])\n","\n","    notes_input_sequence.append(i1)\n","    durations_input_sequence.append(i2)\n","    \n","    if len(notes_input_sequence) > max_seq_len:\n","        notes_input_sequence = notes_input_sequence[1:]\n","        durations_input_sequence = durations_input_sequence[1:]\n","        \n","    if note_result == 'START':\n","        break\n","\n","overall_preds = np.transpose(np.array(overall_preds)) \n","print('Generated sequence of {} notes'.format(len(prediction_output)))"]},{"cell_type":"markdown","metadata":{},"source":["---------------------------------------\n","# Intrepreting Model"]},{"cell_type":"markdown","metadata":{},"source":["-------------------------------------------\n","## Heatmap"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:29:35.525069Z","iopub.status.busy":"2022-03-16T03:29:35.52443Z","iopub.status.idle":"2022-03-16T03:29:36.436508Z","shell.execute_reply":"2022-03-16T03:29:36.435568Z","shell.execute_reply.started":"2022-03-16T03:29:35.525017Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(15,15))\n","ax.set_yticks([int(j) for j in range(35,70)])\n","plt.imshow(overall_preds[35:70,:], origin=\"lower\", cmap='coolwarm', vmin = -0.5, vmax = 0.5, extent=[0, max_extra_notes, 35,70])\n","plt.xlabel(\"Note number\",fontsize=20)\n","plt.ylabel(\"Pitch value (MIDI number)\",fontsize=20)\n","plt.title(\"Probability distribution of the next possible note over time\",fontsize=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:24.634201Z","iopub.status.busy":"2022-03-16T03:02:24.633955Z","iopub.status.idle":"2022-03-16T03:02:24.843924Z","shell.execute_reply":"2022-03-16T03:02:24.843343Z","shell.execute_reply.started":"2022-03-16T03:02:24.634164Z"},"trusted":true},"outputs":[],"source":["output_folder = os.path.join(run_folder, 'output')\n","\n","midi_stream = stream.Stream()\n","\n","# create note and chord objects based on the values generated by the model\n","for pattern in prediction_output:\n","    note_pattern, duration_pattern = pattern\n","    # pattern is a chord\n","    if ('.' in note_pattern):\n","        notes_in_chord = note_pattern.split('.')\n","        chord_notes = []\n","        for current_note in notes_in_chord:\n","            new_note = note.Note(current_note)\n","            new_note.duration = duration.Duration(duration_pattern)\n","            new_note.storedInstrument = instrument.Violoncello()\n","            chord_notes.append(new_note)\n","        new_chord = chord.Chord(chord_notes)\n","        midi_stream.append(new_chord)\n","    elif note_pattern == 'rest':\n","    # pattern is a rest\n","        new_note = note.Rest()\n","        new_note.duration = duration.Duration(duration_pattern)\n","        new_note.storedInstrument = instrument.Violoncello()\n","        midi_stream.append(new_note)\n","    elif note_pattern != 'START':\n","    # pattern is a note\n","        new_note = note.Note(note_pattern)\n","        new_note.duration = duration.Duration(duration_pattern)\n","        new_note.storedInstrument = instrument.Violoncello()\n","        midi_stream.append(new_note)\n","\n","midi_stream = midi_stream.chordify()\n","timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n","new_file = 'output-' + timestr + '.mid'\n","midi_stream.write('midi', fp=os.path.join(output_folder, new_file))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:24.845595Z","iopub.status.busy":"2022-03-16T03:02:24.844868Z","iopub.status.idle":"2022-03-16T03:02:31.864417Z","shell.execute_reply":"2022-03-16T03:02:31.863342Z","shell.execute_reply.started":"2022-03-16T03:02:24.845562Z"},"trusted":true},"outputs":[],"source":["new_path = '/kaggle/working/output/'+new_file\n","fs = FluidSynth()\n","fs.midi_to_audio(new_path, 'new_output.wav')"]},{"cell_type":"markdown","metadata":{},"source":["---------------------------------------\n","## Attention\n","\n","![](https://miro.medium.com/max/1400/1*2dLzmSops3jTvTR1wzRX0w.gif)\n","Picture Credit: https://miro.medium.com\n","\n","In order to determine which notes or sequence of notes may follow a particular passage, it is important to use earlier information far back in the sequence, not the most recent information. A good way to solve this problem is attention. In the attention mechanism, the model builds a context vector by weighting the hidden states in the previous time step of the encoder RNN. The attention mechanism is a set of layers that transforms the encoder's previous and current hidden states into additive weights for context vector generation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:48:41.808438Z","iopub.status.busy":"2022-03-16T03:48:41.8081Z","iopub.status.idle":"2022-03-16T03:48:45.149716Z","shell.execute_reply":"2022-03-16T03:48:45.149005Z","shell.execute_reply.started":"2022-03-16T03:48:41.808407Z"},"trusted":true},"outputs":[],"source":["if use_attention:\n","    fig, ax = plt.subplots(figsize=(20,20))\n","    im = ax.imshow(att_matrix[(seq_len-2):,], cmap='coolwarm', interpolation='nearest')    \n","\n","    # Minor ticks\n","    ax.set_xticks(np.arange(-.5, len(prediction_output)- seq_len, 1), minor=True);\n","    ax.set_yticks(np.arange(-.5, len(prediction_output)- seq_len, 1), minor=True);\n","\n","    # Gridlines based on minor ticks\n","    ax.grid(which='minor', color='black', linestyle='-', linewidth=1)    \n","    \n","    # We want to show all ticks...\n","    ax.set_xticks(np.arange(len(prediction_output) - seq_len))\n","    ax.set_yticks(np.arange(len(prediction_output)- seq_len+2))\n","    # ... and label them with the respective list entries\n","    ax.set_xticklabels([n[0] for n in prediction_output[(seq_len):]])\n","    ax.set_yticklabels([n[0] for n in prediction_output[(seq_len - 2):]])\n","    ax.xaxis.tick_top()    \n","    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"left\", va = \"center\", rotation_mode=\"anchor\")\n","    plt.xlabel(\"sequence of generated notes\",fontsize=20)\n","    plt.ylabel(\"The point of attention\",fontsize=20)\n","    plt.title(\"The amount of attention given to the network hidden state\",fontsize=30)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["The attention mechanism helps the network determine which of the previous states of the circulating layer is important for successive sequence prediction. The encoder-decoder network predicts the note sequence using the RNN decoder, rather than creating a sequence one note at a time."]},{"cell_type":"markdown","metadata":{},"source":["-----------------------------------\n","# Let's compare the original performance with the new one."]},{"cell_type":"markdown","metadata":{},"source":["---------------------------------------\n","## Let's listen originals"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:35.705582Z","iopub.status.busy":"2022-03-16T03:02:35.702732Z","iopub.status.idle":"2022-03-16T03:02:38.784404Z","shell.execute_reply":"2022-03-16T03:02:38.783252Z","shell.execute_reply.started":"2022-03-16T03:02:35.705322Z"},"trusted":true},"outputs":[],"source":["IPython.display.Audio(\"bach_846.wav\") "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:38.788466Z","iopub.status.busy":"2022-03-16T03:02:38.788053Z","iopub.status.idle":"2022-03-16T03:02:40.733019Z","shell.execute_reply":"2022-03-16T03:02:40.728941Z","shell.execute_reply.started":"2022-03-16T03:02:38.788424Z"},"trusted":true},"outputs":[],"source":["IPython.display.Audio(\"bach_847.wav\") "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:40.742871Z","iopub.status.busy":"2022-03-16T03:02:40.738779Z","iopub.status.idle":"2022-03-16T03:02:42.404939Z","shell.execute_reply":"2022-03-16T03:02:42.399907Z","shell.execute_reply.started":"2022-03-16T03:02:40.742618Z"},"trusted":true},"outputs":[],"source":["IPython.display.Audio(\"bach_850.wav\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:42.411329Z","iopub.status.busy":"2022-03-16T03:02:42.41017Z","iopub.status.idle":"2022-03-16T03:02:57.306915Z","shell.execute_reply":"2022-03-16T03:02:57.305912Z","shell.execute_reply.started":"2022-03-16T03:02:42.411205Z"},"trusted":true},"outputs":[],"source":["original_score.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:57.309097Z","iopub.status.busy":"2022-03-16T03:02:57.308825Z","iopub.status.idle":"2022-03-16T03:02:57.43576Z","shell.execute_reply":"2022-03-16T03:02:57.434865Z","shell.execute_reply.started":"2022-03-16T03:02:57.309065Z"},"trusted":true},"outputs":[],"source":["new_score = converter.parse(new_path).chordify()"]},{"cell_type":"markdown","metadata":{},"source":["-------------------------------\n","## Newly composed music\n","\n","Finally, let's listen to the music we made with our model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:57.437716Z","iopub.status.busy":"2022-03-16T03:02:57.437236Z","iopub.status.idle":"2022-03-16T03:02:57.473984Z","shell.execute_reply":"2022-03-16T03:02:57.472765Z","shell.execute_reply.started":"2022-03-16T03:02:57.437671Z"},"trusted":true},"outputs":[],"source":["IPython.display.Audio(\"new_output.wav\") "]},{"cell_type":"markdown","metadata":{},"source":["Wow! Very interesting music was made. It is similar to the previous three songs, but something is different."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-16T03:02:57.475791Z","iopub.status.busy":"2022-03-16T03:02:57.475394Z","iopub.status.idle":"2022-03-16T03:02:58.103502Z","shell.execute_reply":"2022-03-16T03:02:58.102826Z","shell.execute_reply.started":"2022-03-16T03:02:57.475749Z"},"trusted":true},"outputs":[],"source":["new_score.show()"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"border: solid 3px blue;\">"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"}},"nbformat":4,"nbformat_minor":4}
